


The link for model compression or knowledge distillation can be found in [this repository](https://github.com/intersun/PKD-for-BERT-Model-Compression.git).
Please go through the instruction to recreate the kd model
